\subsection{What needs to be known?}

Research in multi-data types have assumed that LSTMs and autoencoders work well at processing combined inputs.  Yet, this has not been shown to be true.  Rather, research by Ngiam et al. found that RBMs tended to not learn combined representations because the single data type signals were strong enough to control the network weights (2011).  Even when LSTMs have been used with multi-data type datasets, they have only been used to translate from one data type to another.  Moreover, LSTM performance on multi-data type datasets was largely a factor of increased memory (Ji Lee, 2016).  This leaves a gap for a methodology that analyzes multi-data type datasets.  

A large research gap is detecting that joint data type features exist.  Research has no methods for detecting if correlated features exist between two data types.  The knowledge that correlated features exist give incentive to data users to exploit these correlations to create better machine learning models.   This paper sees the ability to detect correlated features within multi-data type datasets as a significant knowledge gap that could aid analysis future researchers and help train many datasets.

Another gap is an architecture for processing multi-type datasets. In light of most research analyzing each data type separately, there has been less research trying to combine data types.  The reason for this problem is that each data type performance is very different on CNNs vs NNs.  Yet, if research could propose an architecture for combining the data, beyond an auto-encoder or RBM, that architecture could prove useful discovering new features on these multi-type datasets.
