
\chapter{Problem}
There is a growing problem within many IT fields.  IT is experiencing a massive growth in data.  This data is large, diverse, and differently structured.  The massive amount of diverse and unstructured data provides a problem in both processing and understanding this data.  Often data is not simply text data.  Rather, the data might contain videos, images, or audio data.  The ability to understand and process this data can be important to researcher's within this growing field.  While there exist tools that can process text data, or which process image data, there is a lack of tools or methods for analyzing text and image data.  The field finds itself fast growing and with a multitude of data.  Yet, current methods are limited in ways to analyze this data.  Existing analysis methods work on single types.  There are few existing models or methods for analyzing data comprised of multiple data types.  This leaves researcher's ill-equipped for tackling problems composed of multiple data types.  This paper explores analyzing datasets comprised on image and text data.  proposes ways to analyze a combination of text and image data.  It is hoped that these methods will apply to other multi-data type datasets and further the field's understanding of multi-type datasets.  

\chapter{Overview of the Topic}

Applied machine learning is a large topic.  It takes the topics and tools of machine learning and theorizes applications for the real-world.  The research explores new ways to represent, manipulate, and guide data analysis with machine learning tools.  The research often creates new architectures that perform better in an applied scenario.  Another subject are new ways to draw data out of existing datasets.  This research explores the latter research arena.  The rest of this chapter will give overview explanations of machine learning models and popular tools within the field of applied machine learning.

There are many tools within machine learning. Most tools and models consist of nodes and layers.  The node and layer architecture provides flexible methods for learning and memorizing new data.  Extra layers provide opportunity for models to extract more data.  The combination of nodes and layers allow for different machine learning architectures for learning new data.  Recent research has expanded upon nodes and layers to create more advanced architectures.  Some of these architectures have been labeled as deep, denoting the many layers they contain. Other advances connect nodes in new ways, like connecting nodes to previous layers, which is seen in Recurrent Neural Networks (RNNs).  Each architecture and configuration has different benefits and learns data differently.  Some of these architectures will be more deeply convered in subsequent sections.  

It is worth a quicker dive into the basic mechanics of machine learning models. Machine learning models take inputs.  These inputs are transformed by models into outputs.  There are many manipulations on the data while it passes through the models.  The outputs depend on the type of machine learning.  Two common tasks within machine learning are classification and regression.  Classification models tend to output a probability for each classification through the final layer, known as the softmax layer.  How the input is manipulated depends on the type of machine learning model.  One common type of machine learning model is an Artificial Neural Network (ANNs), which apply simple functions to the inputs, such as a signoid, relu, or tanh function.  The model is generally composed of a few layers, where each node is connected to each node in its subsequent layer.  The network's input weights, for each layer, are adjusted based on the model's error.  The Convolutional Neural Network (CNNs) is similar.  The CNN is also composed of nodes.  Half of the CNN learning is the same as ANNs, i.e. nodes connect to one another and go through a simple learning function like relu.  The difference with CNNs is how the layers are connected.  Instead of connecting all layers together, CNNs split the data up into regional chunks, e.g. the upper right array of data.  The region of datas are connected.  One intersting behavior from the CNN is that region sizes are halved and joined.  In this way, regional behavior is captured and joined together in the output.  Another major type of machine learning model is a Recurrent Neural Network (RNNs).  RNNs are very similar to ANNs, except their layers are connected differently.  The RNNs layers do not always connect to the next layer, i.e. the layer's output may serve as input to a previous/the same layer.  This provides a cycle of input output information within the neural network.  This allows each layer to have some input from future layers, which creates a sense of network memory, where previous data serves as input to the network's current behavior.  

Machine learning models are often applied in particular ways.  For example, CNNs are often applied to images because they learn regional data well.  NN are often applied to text data because they are simple and can memorize the word distributions for langauges.  RNNs are often applied to videos because they can remember data from past inputs.  As will be covered more below, each of these simple models is regularly applied to single data types.  Applying these models to multiple data types will be covered in the related work and later sections.  

There are many major threads under development in the arena of applied machine learning.  These pertain to machine learning with each type of data.  The most popular types of data that receive attention when researchers theorize about their use and possible applications are text, audio, visual, and time-series data.  These data types are popular because they are commonly available.  Such data are available in public repositories of data or through application APIs, such as text and image data that is available from utilizing the Twitter API.  Each data type has multiple facets.  More interestingly, certain machine learning algorithms perform better and differently for particular data types.  Neural Networks (NNs) perform very well on simple text learning tasks, yet struggle to learn image data.  Convolutional Neural Networks (CNNs) may underperform with text-analysis, but have excelled at image-analysis.  Video analysis tends to use Long-Term Short Memory nodes (LSTMs), but often incorporate CNNs, since videos are composed of many images.

While there are many techniques for analyzing different types of data, society and academia has seen an increase in the amount of available data.  Moreover, not all data is the same.  There are many types of video data.  There is still video data, moving video data, video at night, day, in different places, and with more people.  These data differences exist in text data too.  A researcher can analyze text data from Twitter, which looks different than text data from a research paper, which also looks different from text data translated from audio data.  The different data types and variations within data types are a challenge for researchers.  The creation of theories about Twitter text data represents advances in our knowledge of social media.  Creating models that are better at understanding text data that is created from audible speech can further research's understanding of text sentence structure.  These examples only illustrate that there are many ways to approach each data type, and each data type provides many ways to explore and understand its data.

When providing new machine learning insights, whether it be theories or achitectures, those theories need to be validated.  It is very common for papers to cite benchmark models on publically available data as a reference point for model performance.  There are many such benchmarks within the field of applied machine learning.  Many of these benchmarks are the performance of well-tuned machine learning algorithms on a given set of data.  Though this paper will not create a model and apply it to a benchmark, it will cite potential benchmarks for new papers or models implementing the theories presented.


\chapter{Paper Overview}
The related work will begin with an overview of the current tools used by researchers and how these are used.  This section will highlight that these tools are only applied to single data types, such as CNNs used for images, NN for text, and RNNs for video or translation work.  The related work will then delve into research using multiple models and multiple data types.  The reader will see that Restricted Boltzman Machines and auto-encoders are almost exclusively applied to multi-model and multi-type datasets.  In light of the restricted exploration of multi-data type datasets and almost exclusive use of RBMs, the related work will cover more advanced architectures that work with or between multiple data types.

The next sections will delineate where this topic sits within IT.  Those sections will provide brief summaries of the topic, related work, and what needs to be known for this problem.  The paper will then present why the topic is interesting, important, and helpful to those outside the research community.  The next section will propose a research gap and provide research questions.

The next section will discuss open problems in the IT community and discuss the research's possible contributions to both research and practice.  After addressing the overall problem and proposed solution, the research will discuss philosophical assumptions this paper makes.  Part of this paper also proposes new ways to understand datasets comprised on multiple data types.  These assumptiosn will be discusssed alongside its philosphical assumptions.

The paper will then begin to explain its plan of investigation and how to validate the research's results.  The paper will take a two-sided approach and explain qualitative and quantitative methods for its proposed research.  The paper will shortly discuss implications of its methodology like data collection and analysis and provide a final conclusion about the proposed approach, methodology, and theory provided by the paper.
