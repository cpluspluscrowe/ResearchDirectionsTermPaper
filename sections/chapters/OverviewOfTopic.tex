\section{Overview of Applied Machine Learning}

Applied machine learning is a large topic.  It takes the topics and tools of machine learning and theorizes applications for the real-world.  The research explores new ways to represent, manipulate, and guide data analysis with machine learning tools.  The research often creates new architectures that perform better in an applied scenario. There are many tools within machine learning.  Machine learning architecture is also very flexible.  For example, each machine learning model can consist of a varing number of layers, nodes, and even submodels.  Moreover, machine learning behavior depends on its input.  Some of the papers covered in the related work will explore how data manipulations can further the performance of existing machine learning models.  For example, it has been shown that providing regularization produces a model that performs better on new data.  Furthermore, there are many ways and techniques to apply regularization.  Newer theories have proposed new techniques for regularization.  Moreover, many of these new techniques may apply to certain types of machine learning architectures or nodes, such as new forms of regularization for LSTM nodes.  Of particular interest to my research has included techniques for handling multi-varied types of input.  For example, my masters thesis explored the combination of text and image data within a single machine learning model.  These types of advanced machine learning pipelines drive big data, big analysis, and ways to analyze complicated data.  I plan on continuing to drive my research within the direction of exploring new ways to handle various inputs with different data types.  The field of applied machine learning is vast and full of opportunity for new researchers to discover new theories and make innovations in the use, application, and understanding of machine learning.


From the related work covered in this paper, there are major threads under development in the arena of applied machine learning.  These pertain to machine learning with each type of data.  The most popular types of data that receive attention when researchers theorize about their use and possible applications are text, audio, visual, and time-series data.  These data types are popular because they are commonly available.  Such data are available in public repositories of data or through application APIs, such as text and image data that is available from utilizing the Twitter API.  Each data type has multiple facets.  More interestingly, certain machine learning algorithms perform better and differently for particular data types.  Neural Networks (NNs) perform very well on simple text learning tasks, yet struggle to learn image data.  Convolutional Neural Networks (CNNs) may underperform with text-analysis, but have excelled at image-analysis.  Video analysis tends to use Long-Term Short Memory nodes (LSTMs), but often incorporate CNNs, since videos are composed of many images.

While there are many techniques for analyzing different types of data, society and academia has seen an increase in the amount of available data.  Moreover, not all data is the same.  There are many types of video data.  There is still video data, moving video data, video at night, day, in different places, and with more people.  These data differences exist in text data too.  A researcher can analyze text data from Twitter, which looks different than text data from a research paper, which also looks different from text data translated from audio data.  The different data types and variations within data types are a challenge for researchers.  The creation of theories about Twitter text data represents advances in our knowledge of social media.  Creating models that are better at understanding text data that is created from audible speech can further research's understanding of text sentence structure.  These examples only illustrate that there are many ways to approach each data type, and each data type provides many ways to explore and understand its data.

There are many benchmarks within the field of applied machine learning.  Many of these benchmarks are the performance of well-tuned machine learning algorithms on a given set of data.  It is common for papers within the field of applied machine learning to attempt to improve upon machine learning model performance benchmarks with new tools or techniques.  Another common occurrence is to create an architecture that performs well on new data, or with a new aspect of data.  The paper will then apply the machine learning architecture against existing benchmarks to show it performs similarly well on the data.  It is common to apply the machine learning architecture to existing benchmarks as a litmus test of the machine learning model's overall performance.




Many of the articles I read during my survey in the field of machine learning concerned improvements in existing 
