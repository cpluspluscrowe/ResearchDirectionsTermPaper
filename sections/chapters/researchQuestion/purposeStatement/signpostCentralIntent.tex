\subsection{Signpost that establishes the central intent for the study?}

My thesis was two-fold, initially it was creating simple neural network and convolutional neural networks in order to perform prediction on advertisements.
Each network regressed and output that represented how well the advertisement performed on social media.  The second goal of my thesis was to somehow combine my analysis of NN and CNNs.
The initial ideas were to average their regressed outputs, as an average equally weights outputs from both models.  Another idea was to feed each output into a new machine learning model.  The outputs from the NN and CNN were fed into a decision tree,
hoping that the decision tree would create a result that performed better than simple averaging.  The decision tree was slightly beneficial, but overall the combination of the two models performed worse than each individual model.
The result denoted that there was no obvious or simple way to combine machine learning models, especially models that were comprised of different data types, e.g. images and text data.

The really interesting and fun part of the thesis occurred while exploring ways to combine the NN and CNN models.  The decided upon plan-of-action was to try another method for combining the NN and CNN.
The thesis attempted to combine the the NN and CNN mid-model.  The important observation was that most of the model's computations were finished before the model's final output layer.
The model's could be combined at the n-1 layer.  This allowed each model to stay mostly independent, while combining their data.  The result was a final model that performed better than the NN or CNN model.  The thesis found that combining models of different data types is interesting, difficult, and worth exploring.  The topic of combining models of different data types offers a lot of promise.  If researcher's can find better ways to model complex data, i.e. data that contains multiple data types, then researcher's and practitioners will have better tools for analyzing real-world data.  Most data in the world is complex, interconnected, and can be represented in many ways.  For example, medical diagnosing patients makes use of visual data, e.g. X-Rays and a set of symptons, which can be represented as text data.  Having ways to combine the analysis of text and image data can produce models that make better predictions on these datasets.

The central intent for my research is developing methods and machine learning architectures that best process a combination of image and text inputs. The research will investigate ways to manipulate inputs and formulate architectures to handle these types of data inputs.  Central to many of the related works were architectures and methods to process the data differently.  Current reserach is full of methods and architectures for processing data. It is feasible that some of these methods can be combined or leveraged to work well on a combination of text and image data.

One such interesting method for combining the analysis of image and text data is to make use of attention from machine learning models to remember which combinations of text and image data are most important.  The method begins with two shallow models, a text-based model and image-based model.  The models are attention models and track which input sequences are most important.  A third combination model can be built using the two independent models.  The third model can use the attention layers from each models.  In this way, the new model looks for the most important input sequences for the text-based and image-based models. It seems like the one hidden layer that makes use of the text-based and image-based hidden layers might be robust enough to create a combined model that performs well on the data by paying special attention to the most important input features.  It would be interesting to see how the behavior of the model changes if another hidden layer is added to the model, sicne this would be combining the most important inputs from each model.  This combination of the models is similar to the thesis methodology, which worked well.

Another method is to iteratively build the combined model.  I propose that text-based and image-based models are built.  I propose that a combined model begins with the inputs of the text and image-based data. For each new layer of the combined model, I propose that the hidden layers and their weights from the text and image-based models are added to the combined model. This allows the combined model to garner important data from each individual text/image-based model while analyzing their combination within the main layer.  The added layers can be frozen so that their weights don't change with training.  Only the original layers, which are not from the text/image based models undergo training.  This allows the model to train on the relationships between the image and text relations in the model.


