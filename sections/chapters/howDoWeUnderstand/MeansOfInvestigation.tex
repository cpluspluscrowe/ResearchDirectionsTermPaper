\section{Means of Investigation} % (Methodology)

Benchmark datasets already exist for multi-data type datasets.  Many of these datasets and performance metrics are on Kaggle and mentioned in the related work.  The benchmarks are useful because they provide the data for the experiment.  The benchmarks are also reference points for model performance and training time.  Moreover, there are many types of benchmarks containing text and image data.  This allows for the methodology to be tested for regression and classification performance.  This simplifies testing the methodology for multi-type datasets.

There are more nuanced aspects of the research question.  One such nuance is the assertion that the model will perform boosting on the dataset.  Boosting is a common machine learning technique and creates weak models that perform slightly better than random chance (Schapire et al., 2002).  One means of investigation will use existing boosting libraries to create an ensemble of boost models from the CNN architecture.  The investigation will be if the boosting library is able to generate weak models from the CNNs, implying that it is possible to create weak models from NNs.  

Building on the combined model, another means of investigation will be the performance of the final ensemble of models.  These models will contain a trained NN text-based model, CNN image-based model, and the ensemble of combined CNN models.  One means of investigation will be the classification accuracy/regression performance of averaging ball three models on a dataset.


\input{sections/chapters/howDoWeUnderstand/investigation/qualitativeInductive}
\input{sections/chapters/howDoWeUnderstand/investigation/qualitativeDeductive}

